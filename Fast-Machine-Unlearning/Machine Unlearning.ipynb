{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9584dc74",
   "metadata": {},
   "source": [
    "# Machine Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e828435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffde5f739f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73d496",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e04a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def training_step(model, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out = model(images)                  \n",
    "    loss = F.cross_entropy(out, labels) \n",
    "    return loss\n",
    "\n",
    "def validation_step(model, batch):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    out = model(images)                    \n",
    "    loss = F.cross_entropy(out, labels)   \n",
    "    acc = accuracy(out, labels)\n",
    "    return {'Loss': loss.detach(), 'Acc': acc}\n",
    "\n",
    "def validation_epoch_end(model, outputs):\n",
    "    batch_losses = [x['Loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()   \n",
    "    batch_accs = [x['Acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()      \n",
    "    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n",
    "\n",
    "def epoch_end(model, epoch, result):\n",
    "    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n",
    "    \n",
    "def distance(model,model0):\n",
    "    distance=0\n",
    "    normalization=0\n",
    "    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n",
    "        space='  ' if 'bias' in k else ''\n",
    "        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n",
    "        current_norm=p.data0.pow(2).sum().item()\n",
    "        distance+=current_dist\n",
    "        normalization+=current_norm\n",
    "    print(f'Distance: {np.sqrt(distance)}')\n",
    "    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n",
    "    return 1.0*np.sqrt(distance/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec89a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [validation_step(model, batch) for batch in val_loader]\n",
    "    return validation_epoch_end(model, outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
    "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = training_step(model, batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            lrs.append(get_lr(optimizer))\n",
    "            \n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        epoch_end(model, epoch, result)\n",
    "        history.append(result)\n",
    "        sched.step(result['Loss'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6d890",
   "metadata": {},
   "source": [
    "## Train/Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32155eed",
   "metadata": {},
   "source": [
    "### load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b41e0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./cifar10.tgz\n",
      "['train', 'test']\n",
      "['bird', 'horse', 'dog', 'frog', 'airplane', 'ship', 'cat', 'automobile', 'deer', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Dowload the dataset\n",
    "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
    "download_url(dataset_url, '.')\n",
    "\n",
    "# Extract from archive\n",
    "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
    "    tar.extractall(path='./data')\n",
    "    \n",
    "# Look into the data directory\n",
    "data_dir = './data/cifar10'\n",
    "print(os.listdir(data_dir))\n",
    "classes = os.listdir(data_dir + \"/train\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29db69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a417a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageFolder(data_dir+'/train', transform_train)\n",
    "valid_ds = ImageFolder(data_dir+'/test', transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7844cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f4d2b",
   "metadata": {},
   "source": [
    "### Train and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54996a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = resnet18(num_classes = 10).to(device = device)\n",
    "\n",
    "epochs = 40\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6352284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.01000, train_loss: 1.7592, val_loss: 1.4884, val_acc: 0.4508\n",
      "Epoch [1], last_lr: 0.01000, train_loss: 1.2569, val_loss: 1.2470, val_acc: 0.5604\n",
      "Epoch [2], last_lr: 0.01000, train_loss: 1.0357, val_loss: 1.1645, val_acc: 0.6098\n",
      "Epoch [3], last_lr: 0.01000, train_loss: 0.8965, val_loss: 1.0545, val_acc: 0.6422\n",
      "Epoch [4], last_lr: 0.01000, train_loss: 0.8126, val_loss: 0.9064, val_acc: 0.6882\n",
      "Epoch [5], last_lr: 0.01000, train_loss: 0.7636, val_loss: 0.8728, val_acc: 0.6967\n",
      "Epoch [6], last_lr: 0.01000, train_loss: 0.7182, val_loss: 0.8450, val_acc: 0.7124\n",
      "Epoch [7], last_lr: 0.01000, train_loss: 0.6804, val_loss: 0.9484, val_acc: 0.6863\n",
      "Epoch [8], last_lr: 0.01000, train_loss: 0.6523, val_loss: 0.8761, val_acc: 0.7152\n",
      "Epoch [9], last_lr: 0.01000, train_loss: 0.6295, val_loss: 0.8406, val_acc: 0.7147\n",
      "Epoch [10], last_lr: 0.01000, train_loss: 0.6025, val_loss: 0.8402, val_acc: 0.7112\n",
      "Epoch [11], last_lr: 0.01000, train_loss: 0.5883, val_loss: 0.7504, val_acc: 0.7469\n",
      "Epoch [12], last_lr: 0.01000, train_loss: 0.5664, val_loss: 0.8018, val_acc: 0.7291\n",
      "Epoch [13], last_lr: 0.01000, train_loss: 0.5529, val_loss: 0.8022, val_acc: 0.7303\n",
      "Epoch [14], last_lr: 0.01000, train_loss: 0.5390, val_loss: 0.7993, val_acc: 0.7302\n",
      "Epoch [15], last_lr: 0.01000, train_loss: 0.5226, val_loss: 0.8056, val_acc: 0.7302\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch [16], last_lr: 0.00500, train_loss: 0.3608, val_loss: 0.7988, val_acc: 0.7529\n",
      "Epoch [17], last_lr: 0.00500, train_loss: 0.3090, val_loss: 0.8140, val_acc: 0.7583\n",
      "Epoch [18], last_lr: 0.00500, train_loss: 0.2924, val_loss: 0.8451, val_acc: 0.7496\n",
      "Epoch [19], last_lr: 0.00500, train_loss: 0.2782, val_loss: 0.8708, val_acc: 0.7498\n",
      "Epoch    20: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch [20], last_lr: 0.00250, train_loss: 0.1434, val_loss: 0.8949, val_acc: 0.7712\n",
      "Epoch [21], last_lr: 0.00250, train_loss: 0.0763, val_loss: 1.0818, val_acc: 0.7623\n",
      "Epoch [22], last_lr: 0.00250, train_loss: 0.0824, val_loss: 1.1349, val_acc: 0.7564\n",
      "Epoch [23], last_lr: 0.00250, train_loss: 0.1045, val_loss: 1.1233, val_acc: 0.7599\n",
      "Epoch    24: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch [24], last_lr: 0.00125, train_loss: 0.0469, val_loss: 1.1188, val_acc: 0.7725\n",
      "Epoch [25], last_lr: 0.00125, train_loss: 0.0137, val_loss: 1.1850, val_acc: 0.7746\n",
      "Epoch [26], last_lr: 0.00125, train_loss: 0.0073, val_loss: 1.2403, val_acc: 0.7744\n",
      "Epoch [27], last_lr: 0.00125, train_loss: 0.0045, val_loss: 1.2713, val_acc: 0.7750\n",
      "Epoch    28: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch [28], last_lr: 0.00063, train_loss: 0.0028, val_loss: 1.2916, val_acc: 0.7737\n",
      "Epoch [29], last_lr: 0.00063, train_loss: 0.0022, val_loss: 1.3018, val_acc: 0.7766\n",
      "Epoch [30], last_lr: 0.00063, train_loss: 0.0022, val_loss: 1.3134, val_acc: 0.7757\n",
      "Epoch [31], last_lr: 0.00063, train_loss: 0.0018, val_loss: 1.3465, val_acc: 0.7746\n",
      "Epoch    32: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch [32], last_lr: 0.00031, train_loss: 0.0016, val_loss: 1.3443, val_acc: 0.7741\n",
      "Epoch [33], last_lr: 0.00031, train_loss: 0.0016, val_loss: 1.3684, val_acc: 0.7740\n",
      "Epoch [34], last_lr: 0.00031, train_loss: 0.0015, val_loss: 1.3750, val_acc: 0.7742\n",
      "Epoch [35], last_lr: 0.00031, train_loss: 0.0015, val_loss: 1.3824, val_acc: 0.7720\n",
      "Epoch    36: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch [36], last_lr: 0.00016, train_loss: 0.0012, val_loss: 1.3703, val_acc: 0.7727\n",
      "Epoch [37], last_lr: 0.00016, train_loss: 0.0011, val_loss: 1.3904, val_acc: 0.7721\n",
      "Epoch [38], last_lr: 0.00016, train_loss: 0.0012, val_loss: 1.3961, val_acc: 0.7715\n",
      "Epoch [39], last_lr: 0.00016, train_loss: 0.0012, val_loss: 1.3970, val_acc: 0.7717\n",
      "Epoch    40: reducing learning rate of group 0 to 7.8125e-05.\n",
      "CPU times: user 3min 56s, sys: 14.3 s, total: 4min 10s\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=weight_decay, \n",
    "                             opt_func=opt_func)\n",
    "\n",
    "torch.save(model.state_dict(), \"ResNET18_CIFAR10_ALL_CLASSES.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980397d",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3769eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Loss': 1.396955132484436, 'Acc': 0.7716739773750305}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\n",
    "history = [evaluate(model, valid_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e31ccb",
   "metadata": {},
   "source": [
    "## Unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f88a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the noise structure\n",
    "class Noise(nn.Module):\n",
    "    def __init__(self, *dim):\n",
    "        super().__init__()\n",
    "        self.noise = torch.nn.Parameter(torch.randn(*dim), requires_grad = True)\n",
    "        \n",
    "    def forward(self):\n",
    "        return self.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65082f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all classes\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# classes which are required to un-learn\n",
    "classes_to_forget = [0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfedd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classwise list of samples\n",
    "num_classes = 10\n",
    "classwise_train = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_train[i] = []\n",
    "\n",
    "for img, label in train_ds:\n",
    "    classwise_train[label].append((img, label))\n",
    "    \n",
    "classwise_test = {}\n",
    "for i in range(num_classes):\n",
    "    classwise_test[i] = []\n",
    "\n",
    "for img, label in valid_ds:\n",
    "    classwise_test[label].append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edbda37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some samples from retain classes\n",
    "num_samples_per_class = 1000\n",
    "\n",
    "retain_samples = []\n",
    "for i in range(len(classes)):\n",
    "    if classes[i] not in classes_to_forget:\n",
    "        retain_samples += classwise_train[i][:num_samples_per_class]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70736605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain validation set\n",
    "retain_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls not in classes_to_forget:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            retain_valid.append((img, label))\n",
    "            \n",
    "# forget validation set\n",
    "forget_valid = []\n",
    "for cls in range(num_classes):\n",
    "    if cls in classes_to_forget:\n",
    "        for img, label in classwise_test[cls]:\n",
    "            forget_valid.append((img, label))\n",
    "            \n",
    "forget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\n",
    "retain_valid_dl = DataLoader(retain_valid, batch_size*2, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9afbe",
   "metadata": {},
   "source": [
    "### Training the Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fcc11a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "model = resnet18(num_classes = 10).to(device = device)\n",
    "model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1170217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optiming loss for class 0\n",
      "Loss: 191.4989776611328\n",
      "Loss: 40.89501953125\n",
      "Loss: 0.3573267459869385\n",
      "Loss: -7.632478713989258\n",
      "Loss: -11.201236724853516\n",
      "Optiming loss for class 2\n",
      "Loss: 192.25242614746094\n",
      "Loss: 41.64573287963867\n",
      "Loss: 0.9134722948074341\n",
      "Loss: -7.104319095611572\n",
      "Loss: -10.688702583312988\n",
      "CPU times: user 1.72 s, sys: 374 ms, total: 2.09 s\n",
      "Wall time: 2.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "noises = {}\n",
    "for cls in classes_to_forget:\n",
    "    print(\"Optiming loss for class {}\".format(cls))\n",
    "    noises[cls] = Noise(batch_size, 3, 32, 32).cuda()\n",
    "    opt = torch.optim.Adam(noises[cls].parameters(), lr = 0.1)\n",
    "\n",
    "    num_epochs = 5\n",
    "    num_steps = 8\n",
    "    class_label = cls\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = []\n",
    "        for batch in range(num_steps):\n",
    "            inputs = noises[cls]()\n",
    "            labels = torch.zeros(batch_size).cuda()+class_label\n",
    "            outputs = model(inputs)\n",
    "            loss = -F.cross_entropy(outputs, labels.long()) + 0.1*torch.mean(torch.sum(torch.square(inputs), [1, 2, 3]))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss.append(loss.cpu().detach().numpy())\n",
    "        print(\"Loss: {}\".format(np.mean(total_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08aa35",
   "metadata": {},
   "source": [
    "## Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09feaed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/visionintelligence/.conda/envs/vikram_torch/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1: 0.16607201647758485,Train Acc:11.248%\n",
      "CPU times: user 990 ms, sys: 50.3 ms, total: 1.04 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 256\n",
    "noisy_data = []\n",
    "num_batches = 20\n",
    "class_num = 0\n",
    "\n",
    "for cls in classes_to_forget:\n",
    "    for i in range(num_batches):\n",
    "        batch = noises[cls]().cpu().detach()\n",
    "        for i in range(batch[0].size(0)):\n",
    "            noisy_data.append((batch[i], torch.tensor(class_num)))\n",
    "\n",
    "other_samples = []\n",
    "for i in range(len(retain_samples)):\n",
    "    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][1])))\n",
    "noisy_data += other_samples\n",
    "noisy_loader = torch.utils.data.DataLoader(noisy_data, batch_size=256, shuffle = True)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.02)\n",
    "\n",
    "\n",
    "for epoch in range(1):  \n",
    "    model.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "    for i, data in enumerate(noisy_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(),torch.tensor(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        out = torch.argmax(outputs.detach(),dim=1)\n",
    "        assert out.shape==labels.shape\n",
    "        running_acc += (labels==out).sum().item()\n",
    "    print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac4a772",
   "metadata": {},
   "source": [
    "### Performance after Impair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfcffec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Standard Forget Model on Forget Class\n",
      "Accuracy: 0.634765625\n",
      "Loss: 9.18183708190918\n",
      "Performance of Standard Forget Model on Retain Class\n",
      "Accuracy: 68.1811511516571\n",
      "Loss: 0.9295864701271057\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance of Standard Forget Model on Forget Class\")\n",
    "history = [evaluate(model, forget_valid_dl)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "print(\"Performance of Standard Forget Model on Retain Class\")\n",
    "history = [evaluate(model, retain_valid_dl)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabdfc92",
   "metadata": {},
   "source": [
    "## Repair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca2abac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/visionintelligence/.conda/envs/vikram_torch/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1: 0.09651499267578124,Train Acc:12.566%\n",
      "CPU times: user 871 ms, sys: 90.4 ms, total: 961 ms\n",
      "Wall time: 960 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "heal_loader = torch.utils.data.DataLoader(other_samples, batch_size=256, shuffle = True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "for epoch in range(1):  \n",
    "    model.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0\n",
    "    for i, data in enumerate(heal_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(),torch.tensor(labels).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        out = torch.argmax(outputs.detach(),dim=1)\n",
    "        assert out.shape==labels.shape\n",
    "        running_acc += (labels==out).sum().item()\n",
    "    print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)},Train Acc:{running_acc*100/len(train_ds)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee6e55",
   "metadata": {},
   "source": [
    "### Performance after Repair Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74aa345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Standard Forget Model on Forget Class\n",
      "Accuracy: 0.0\n",
      "Loss: 10.907428741455078\n",
      "Performance of Standard Forget Model on Retain Class\n",
      "Accuracy: 70.94970941543579\n",
      "Loss: 0.8271207213401794\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance of Standard Forget Model on Forget Class\")\n",
    "history = [evaluate(model, forget_valid_dl)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))\n",
    "\n",
    "print(\"Performance of Standard Forget Model on Retain Class\")\n",
    "history = [evaluate(model, retain_valid_dl)]\n",
    "print(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\n",
    "print(\"Loss: {}\".format(history[0][\"Loss\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
